{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  07 - Unsupervised Learning with Scikit-Learn\n",
        "\n",
        "*HFT Stuttgart, 2024 Summer Term, Michael Mommert (michael.mommert@hft-stuttgart.de)*\n",
        "\n",
        "In this Jupyter Notebook, we explore unsupervised learning with Scikit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ5HdaLST7Rb"
      },
      "source": [
        "In our previous lecture, we discussed different unsupervised learning methods with a focus on **clustering** and **dimensionality reduction**. Today, we will apply some of these methods to different data modalities.\n",
        "\n",
        "## Lab Objectives:\n",
        "* comparing different clustering methods for our Iris data set\n",
        "* clustering applied to image data\n",
        "* dimensionality reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkoodJYHT7Rd"
      },
      "source": [
        "## Clustering the Iris data set\n",
        "\n",
        "We revisit our famous Iris data set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AReySIVnT7Re"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "x = data.data\n",
        "y = data.target\n",
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19LY85S2T7Re"
      },
      "source": [
        "As a quick reminder: the data set (`x`) contains measures features of 150 iris flowers. The features are petal length, petal width, sepal length and sepal width. For each speciment we also know the class of flower it has been attributed to by a botanist (`y`).\n",
        "\n",
        "Let's plot some two-dimensional projections of the four-dimensional data set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMOfyPhkT7Rf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "ax1.scatter(x[:,0], x[:,1])\n",
        "ax1.set_xlabel(data.feature_names[0])\n",
        "ax1.set_ylabel(data.feature_names[1])\n",
        "\n",
        "ax2.scatter(x[:,2], x[:,3])\n",
        "ax2.set_xlabel(data.feature_names[2])\n",
        "ax2.set_ylabel(data.feature_names[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1idLLXAXT7Rg"
      },
      "source": [
        "The plots clearly show structure in the data: if we ignore the labels (since we are doing unsupervised learning here), there seem to be 2 or three clusters in the data. \n",
        "\n",
        "Of course, we do know the ground-truth labels for each of those data points. If we take advantage of these labels, the plot would look like this, exposing the different clusters based on their different class affiliations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4EvJbrFT7Rg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "ax1.scatter(x[:,0], x[:,1], c=y)\n",
        "ax1.set_xlabel(data.feature_names[0])\n",
        "ax1.set_ylabel(data.feature_names[1])\n",
        "\n",
        "ax2.scatter(x[:,2], x[:,3], c=y)\n",
        "ax2.set_xlabel(data.feature_names[2])\n",
        "ax2.set_ylabel(data.feature_names[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KsuzJQFT7Ri"
      },
      "source": [
        "Now let's use some clustering methods to see how well we can identify these clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4DkTVopT7Rj"
      },
      "source": [
        "### K-means\n",
        "\n",
        "\n",
        "We start with a simple $k$-means clustering algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKSnkQHJT7Rj"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# scale the data\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "\n",
        "# train and apply k-Means\n",
        "model = KMeans(n_clusters=2)\n",
        "pred = model.fit_predict(x_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvswBIXST7Rk"
      },
      "source": [
        "Please note how similar the `sklearn` API is to the supervised methods that we got to know two weeks ago. In fact, you might wonder why there is even a `predict` method, since we are only doing unsupervised learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cYareflT7Rk"
      },
      "outputs": [],
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "ax1.scatter(x[:,0], x[:,1], c=pred, alpha=0.5)\n",
        "ax1.set_xlabel(data.feature_names[0])\n",
        "ax1.set_ylabel(data.feature_names[1])\n",
        "\n",
        "ax2.scatter(x[:,2], x[:,3], c=pred, alpha=0.5)\n",
        "ax2.set_xlabel(data.feature_names[2])\n",
        "ax2.set_ylabel(data.feature_names[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGu4dE6nT7Rl"
      },
      "source": [
        "The result looks good for $k=2$ - the two obvious clusters are easily separated.\n",
        "\n",
        "**Question**: What about $k=3$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcjGcg8TT7Rm"
      },
      "source": [
        "## More complex clustering examples\n",
        "\n",
        "### Moons data set\n",
        "\n",
        "We will create a *moons* data set of two intertwined crescents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j69jNFJeT7Rm"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# generate data set\n",
        "x, y = make_moons(n_samples=1000, noise=0.05, random_state=42)\n",
        "x = scaler.fit_transform(x) # scale the data set\n",
        "\n",
        "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
        "ax.scatter(x[:,0], x[:,1], color=[{0: 'red', 1: 'green', 2: 'blue'}[l] for l in y])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfj3-EbT7Rm"
      },
      "source": [
        "We already saw that $k$-Means will fail with this data set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVFJePlaT7Rm"
      },
      "outputs": [],
      "source": [
        "model = KMeans(n_clusters=2)\n",
        "pred = model.fit_predict(x)\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "ax1.scatter(x[:,0], x[:,1], color=[{0: 'red', 1: 'green', 2: 'blue'}[l] for l in y])\n",
        "ax1.set_title('Ground Truth')\n",
        "ax2.scatter(x[:,0], x[:,1], color=[{0: 'red', 1: 'green', 2: 'blue'}[l] for l in pred])\n",
        "ax2.set_title('Prediction')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbldrMRwT7Rn"
      },
      "source": [
        "**Question**: Why does $k$-Means fare badly in this case?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ssHFBBMT7Rn"
      },
      "source": [
        "**Question**: What other clustering method might provide better results in this specific case? Can you implement it here?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt1v0UjKT7Rn"
      },
      "source": [
        "### Noisy data\n",
        "\n",
        "In the following example we will try to reveal clusters in a noisy data set. *Noisy* refers here to the fact that in addition to the different clusters, the data set also contains a number of background data points that do not belong to either cluster. This situation is rather common in real life."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1y6o7UmT7Ro"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from numpy.random import random\n",
        "np.random.seed(42)\n",
        "\n",
        "# generate data set\n",
        "x, y = make_blobs(n_samples=500, n_features=2, random_state=42)\n",
        "x_noise = random((200, 2))*(x.max()-x.min())+x.min()\n",
        "x = np.vstack([x, x_noise])\n",
        "y = np.hstack([y, [-1]*len(x_noise)])\n",
        "\n",
        "f, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
        "ax.scatter(x[:,0], x[:,1], color=[{-1:'gray', 0: 'red', 1: 'green', 2: 'blue'}[l] for l in y])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdfDRssKT7Ro"
      },
      "source": [
        "Let's check $k$-means, assuming that we know that there are 3 clusters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHgpBdglT7Ro"
      },
      "outputs": [],
      "source": [
        "model = KMeans(n_clusters=3)\n",
        "pred = model.fit_predict(x)\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "ax1.scatter(x[:,0], x[:,1], color=[{-1: 'gray', 0: 'red', 1: 'green', 2: 'blue'}[l] for l in y])\n",
        "ax1.set_title('Ground Truth')\n",
        "ax2.scatter(x[:,0], x[:,1], color=[{-1: 'gray', 0: 'red', 1: 'green', 2: 'blue'}[l] for l in pred])\n",
        "ax2.set_title('Prediction')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpJIZcWST7Rp"
      },
      "source": [
        "$k$-Means can identify the clusters properly, but it also picks up all the noise and assigns it to a cluster.\n",
        "\n",
        "\n",
        "**Question**: Is there a clustering method that can deal with noise? If so, implement it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SltYgIitT7Rp"
      },
      "source": [
        "## Clustering of image data\n",
        "\n",
        "We now saw plenty of examples for how to apply clustering methods to numerical data. What about image data? Can we cluster images?\n",
        "\n",
        "Let's download some images of digits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7AYzU7-T7Rp"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "data = load_digits()\n",
        "\n",
        "x = data.data\n",
        "y = data.target\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KlUVNKpT7Rp"
      },
      "source": [
        "What do they look like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrAmY-28T7Rq"
      },
      "outputs": [],
      "source": [
        "x[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bko8g6LjT7Rq"
      },
      "source": [
        "Hmm. That's a linearized image. Let's reshape the vector and plot the result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUfFazzKT7Rq"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x[0].reshape(8 ,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvEqE0SNT7Rr"
      },
      "source": [
        "That's a zero, right?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYpjKCL9T7Rr"
      },
      "outputs": [],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Ln37ZCT7Rr"
      },
      "source": [
        "Correct!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMbSq8IST7Rs"
      },
      "source": [
        "But can we simply apply clustering to the linearized image data? Let's try:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grN1Ih6IT7Rs"
      },
      "outputs": [],
      "source": [
        "model = KMeans(n_clusters=10)\n",
        "pred = model.fit_predict(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1Cw0GvbT7Rs"
      },
      "source": [
        "Ok, but how do we check if it learned anything useful? We can average all image that belong to the same cluster and have a look at the averaged images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J19zUNCyT7Rs"
      },
      "outputs": [],
      "source": [
        "digits = np.empty((10, 64))\n",
        "# create average images \n",
        "for i in range(10):\n",
        "    digits[i] = np.average(x[pred == i], axis=0)\n",
        "\n",
        "# reshape the vectors to 8x8 images\n",
        "digits = digits.reshape(10, 8, 8)\n",
        "\n",
        "f, ax = plt.subplots(2, 5, figsize=(10, 4), sharex=True, sharey=True)\n",
        "ax = np.ravel(ax)\n",
        "\n",
        "for i in range(10):\n",
        "    ax[i].imshow(digits[i])\n",
        "    ax[i].set_xticks([])\n",
        "    ax[1].set_yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9UOt7NgT7Rt"
      },
      "source": [
        "Those look like decent digits. Is it possible that we can cluster these vectorized images of digits with something as simple as $k$-Means?\n",
        "\n",
        "Let's do a quick check: we will extract the ground-truth labels of our cluster members individually:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doXsAmCkT7Rt"
      },
      "outputs": [],
      "source": [
        "y[pred == 4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_tL1_2OT7Rt"
      },
      "source": [
        "Naturally, the digits are off, since the cluster ids are assigned randomly. But it seems to be the case that most samples of the same cluster show the same digit.\n",
        "\n",
        "Think about this for a minute: the images are stored in a 64-dimensional (8x8 image maps) feature space and $k$-means is able to identify the 10 different classes that populate this 64-dimensional feature space with high confidence!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYgDg2MYT7Rt"
      },
      "source": [
        "## Dimensionality reduction with Principal Components Analysis (PCA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okpnIbMUT7Ru"
      },
      "source": [
        "Let's go back to the Iris data set and see whether we can reduce it to a smaller dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRI_KWq1T7Ru"
      },
      "outputs": [],
      "source": [
        "data = load_iris()\n",
        "x = data.data\n",
        "y = data.target\n",
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAxaEX-XT7Ru"
      },
      "source": [
        "Let's have a look at the pair plot for this data set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXZ47UPJT7Ru"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "iris_plot = sns.load_dataset(\"iris\")\n",
        "sns.pairplot(iris_plot, diag_kind='hist', hue='species')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yclZS1jeT7Rv"
      },
      "source": [
        "PCA is very sensitive to data scaling: the mean of the data set should always be zero, the variance in each feature should be unity. This is not the case here. Therefore, we have to apply scaling with the Standard Scaler, which meets these requirements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi12t-7ZT7Rv"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3L47hwDT7Rv"
      },
      "source": [
        "Let's apply the PCA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiUEgnhGT7Rw"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=4)\n",
        "\n",
        "pca.fit(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO7r1ObzT7Rw"
      },
      "source": [
        "Note that we derive 4 principal components here: this is the maximum number of components. We do not have to use all of them later. By default, all principal components are ordered by importance, the first one being the most important one, the last one being the least important one. Therefore, we can simply extract a slice of the prinicipal components (we will do this later).\n",
        "\n",
        "Let's have a quick look at the shape of the principal components:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4co09UqpT7Rw"
      },
      "outputs": [],
      "source": [
        "pca.components_.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ4jUnarT7Rw"
      },
      "source": [
        "Of course, this representation is symmetric (4 original features and 4 principal components). Interpreted as a matrix, the rows refer to the different principal components, the columns refer to the original feature vectors based on which the principal components are described.\n",
        "\n",
        "We can now transform any data point into a representation based on the principal components:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Rr_zfsST7Rx"
      },
      "outputs": [],
      "source": [
        "pca.transform(x[0].reshape(1, -1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNBGGSmXT7Rx"
      },
      "source": [
        "We plan to apply dimensionality reduction. So how many principal components should we keep? Let's have a look at the explained variance for the different components:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRrwM5B4T7Ry"
      },
      "outputs": [],
      "source": [
        "pca.explained_variance_ratio_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTI5xC1KT7Ry"
      },
      "source": [
        "Let's plot the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yD1yXk0OT7Ry"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(1, 5), np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of principal components')\n",
        "plt.ylabel('Cumulative explained variance')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA__n9-iT7Ry"
      },
      "source": [
        "Interesting. We can reduce this data set to only two principal components and this still enables us to reproduce 95.8% of the variance in the data set. Let's rederive the PCA using only two principal components and plot the transformed data set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFn23-80T7Rz"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)\n",
        "x_pca = pca.fit_transform(x)\n",
        "x_pca.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9Prd9qHT7Rz"
      },
      "source": [
        "We plot the transformed data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYKqwLWlT7Rz"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_pca[:,0], x_pca[:,1])\n",
        "plt.xlabel('PCA1')\n",
        "plt.xlabel('PCA2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE9xSGAHT7R0"
      },
      "source": [
        "This looks very similar to some of the pair plots that we saw earlier - which makes sense: performing PCA is the equivalent of rotating the data and projecting it to a lower dimensional space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzctTB7ST7R0"
      },
      "source": [
        "## Performing PCA on image data\n",
        "\n",
        "We will now perform PCA to some image data to get a better understanding of what it does.\n",
        "\n",
        "First we have to download an image data set containing 400 faces of 40 different people. Each sample is a linearized 64x64 image map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZP2FCY-T7R0"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "\n",
        "data = fetch_olivetti_faces()\n",
        "\n",
        "x = data.data\n",
        "y = data.target\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfnAXWsoT7R1"
      },
      "source": [
        "Let's plot the first 100 images in the data set to get a better idea of the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef435TyfT7R1"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(10, 10, figsize=(10, 10))\n",
        "ax = np.ravel(ax)\n",
        "\n",
        "for i in range(100): \n",
        "    ax[i].imshow(x[i].reshape(64,64), cmap='Greys_r')\n",
        "    ax[i].set_xticks([])\n",
        "    ax[i].set_yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j56K8C0qT7R1"
      },
      "source": [
        "Ok, so there's 10 images of each person taken from different angles. \n",
        "\n",
        "The question now is: can we represent this data set in a lower dimensional space (current dimensionality: 4096=64x64)?\n",
        "\n",
        "Let's try PCA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQcoL-70T7R2"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=200)\n",
        "pca.fit(scaler.fit_transform(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8kC4klqT7R2"
      },
      "source": [
        "Let us have a look at the first 10 principal components. Disclaimer: there's some spooky faces..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPYbPEYvT7R2"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(2, 5, figsize=(10, 4))\n",
        "ax = np.ravel(ax)\n",
        "\n",
        "for i in range(10):\n",
        "    ax[i].imshow(pca.components_[i].reshape(64, 64), cmap='Greys_r')\n",
        "    ax[i].set_xticks([])\n",
        "    ax[i].set_yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eWGfXyET7R2"
      },
      "source": [
        "All those principal components look a little bit like faces. Each principal component describes a different set of features in images of faces:\n",
        "* The first component is a dark face with a bright background.\n",
        "* The second component is brighter to the right than to the left.\n",
        "* The third component has dark cheeks.\n",
        "* The fourth component has well-defined eyes and features of glasses.\n",
        "* The fifth component has bright regions around the eyes.\n",
        "\n",
        "... and so on. Each principal components covers different features of faces. This is the **feature selection** part of PCA: the method extracts the most important features.\n",
        "\n",
        "By transforming an original image based on the PCA transformation, we can reassemble that image based on those principal components. Taking advantage of the **dimensionality reduction** part of PCA, we will only utilize a subset of available principal components: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0i5r8DRT7R3"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(1, 5, figsize=(15 ,3))\n",
        "ax = np.ravel(ax)\n",
        "\n",
        "m = 10  # face id\n",
        "\n",
        "ax[0].imshow(x[m].reshape(64, 64), cmap='Greys_r')\n",
        "ax[0].set_title('Ground Truth')\n",
        "\n",
        "for i, j in enumerate([4, 9, 99, 199]):\n",
        "    ax[i+1].imshow(np.sum(pca.transform(x[m].reshape(1, -1))[0, :j]*pca.components_[:j].transpose(), axis=1).reshape(64,64), cmap='Greys_r')\n",
        "    ax[i+1].set_title('{} components'.format(j+1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48a-10lST7R3"
      },
      "source": [
        "Naturally, the more principal components we consider, the better is the quality of the reconstruction. The image quality based on 100 principal components is already pretty good. \n",
        "\n",
        "Make yourself aware what this means: we can store an image of a person with 4096 pixels by storing only 100 values, if we know the corresponding principal components. Pretty neat, right? "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "lab_02.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8a759edab9623fec557173fc5dc3172aac588fd51e2e191f985f3e24b521fb85"
    },
    "kernelspec": {
      "display_name": "Python 3.7.9 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
