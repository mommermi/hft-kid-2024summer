{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dojtwAh1Ww1B"
   },
   "source": [
    "#  08 - Neural Networks\n",
    "\n",
    "*HFT Stuttgart, 2024 Summer Term, Michael Mommert (michael.mommert@hft-stuttgart.de)*\n",
    "\n",
    "This Jupyter Notebook provides a simple introduction into Python programming and is based on Notebooks prepared by the amazing Dr. Marco Schreyer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR4Ywe2HWw1M"
   },
   "source": [
    "In this lab, we will learn how to implement, train, and apply our first **Artificial Neural Network (ANN)** using a Python library named `PyTorch`. The `PyTorch` library is an open-source machine learning library for Python, used for a variety of applications such as image classification and natural language processing. We will use the implemented neural network to learn to again classify images of fashion articles from the **Fashion-MNIST** dataset.\n",
    "\n",
    "The figure below illustrates a high-level view of the machine learning process we aim to establish in this lab:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wgQ_ksmaWw1N"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 700px\" src=\"https://github.com/mommermi/hft-kid-2024summer/blob/main/lab_03/classification.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aut1dJXmWw1O"
   },
   "source": [
    "## 1. Deep Learning Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tb0svb4Ww1O"
   },
   "source": [
    "As a reminder, here is the Deep Learning workflow for training a neural network:\n",
    "\n",
    "<img align=\"center\" style=\"max-width: 700px\" src=\"https://github.com/mommermi/hft-kid-2024summer/blob/main/08_neuralnetworks/dl_pipeline.pdf?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ks081EJEWw1P"
   },
   "source": [
    "## 2. Setup of the Jupyter Notebook Environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mdmhjYHFWw1P"
   },
   "source": [
    "Similar to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. We will mainly use the `PyTorch`, `Numpy`, `Scikit-Learn`, `Matplotlib` and a few utility libraries throughout this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rDvIKj-Ww1P"
   },
   "outputs": [],
   "source": [
    "# import standard python libraries\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heUZY7dgWw1Q"
   },
   "source": [
    "Import the Python machine / deep learning libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RTb4Mc1Ww1Q"
   },
   "outputs": [],
   "source": [
    "# import the PyTorch deep learning libary\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FRpZfSImWw1R"
   },
   "source": [
    "Import the sklearn classification metrics and some other useful tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJ180J4sWw1R"
   },
   "outputs": [],
   "source": [
    "# import sklearn classification evaluation library\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5tatoV81Ww1R"
   },
   "source": [
    "Import plotting capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTSNWwejWw1R"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM3LiXwWWw1S"
   },
   "source": [
    "**Run this cell only if you are running this notebook on Google Colab**: Import `Google's GDrive` connector and mount your `GDrive` directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptQU8CeEWw1S"
   },
   "outputs": [],
   "source": [
    "# import the Google Colab GDrive connector\n",
    "from google.colab import drive\n",
    "\n",
    "# mount GDrive inside the Colab notebook\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# create data sub-directory inside the Colab Notebooks directory\n",
    "data_directory = '/content/drive/MyDrive/Colab Notebooks/data_fmnist'\n",
    "if not os.path.exists(data_directory): os.makedirs(data_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "I81E5iJOwR6x"
   },
   "source": [
    "**Run this cell only if you are running this notebook on Binder**: Create a directory to store the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq5F-BV1wSXL"
   },
   "outputs": [],
   "source": [
    "data_directory = 'data_fmnist/'\n",
    "if not os.path.exists(data_directory): os.makedirs(data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32BCRqyA5cD5"
   },
   "source": [
    "Set a random `seed` value to obtain reproducable results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3cPTu1R5cmj"
   },
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value) # set pytorch seed CPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BHMs9Gf0wakv"
   },
   "source": [
    "Google Colab provides free GPUs for running notebooks. However, if you just execute this notebook as is, it will use your device's CPU (as if you were running the notebook on Bilder or some other cloud computing service). To run the notebook on a GPU at Colab, you have to go to `Runtime` > `Change runtime type` and set the Runtime type to `GPU` in the drop-down. Running this lab on a CPU is fine, but you will find that GPU computing is faster. `cuda:0` indicates that the notebook  is using a GPU.\n",
    "\n",
    "Enable GPU computing by setting the device flag and init a CUDA seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fl2UHzshwdyk"
   },
   "outputs": [],
   "source": [
    "# set cpu or gpu enabled device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
    "\n",
    "# init deterministic GPU seed\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "\n",
    "# log type of device enabled\n",
    "print('[LOG] notebook with {} computation enabled'.format(str(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47HnxJHswf05"
   },
   "source": [
    "Let's determine if we have access to a GPU provided by e.g. `Google's Colab` environment (this will result in an error message, if you do not have access to a GPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "907R1nhVwhXb"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyqnqndjWw1S"
   },
   "source": [
    "## 3. Dataset Download and Data Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgyKo34eWw1T"
   },
   "source": [
    "The **Fashion-MNIST database** is a large database of Zalando articles that is commonly used for training various image processing systems. The database is widely used for training and testing in the field of machine learning. Let's have a brief look into a couple of sample images contained in the dataset:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-q9TexBXWw1T"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 700px; height: 300px\" src=\"https://github.com/mommermi/hft-kid-2024summer/blob/main/lab_03/FashionMNIST.png?raw=1\">\n",
    "\n",
    "Source: https://www.kaggle.com/c/insar-fashion-mnist-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YEOHPO5Ww1T"
   },
   "source": [
    "Further details on the dataset can be obtained via Zalando research's [github page](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B6cw9iEWw1T"
   },
   "source": [
    "The **Fashion-MNIST database** is an image dataset of Zalando's article images, consisting of in total 70,000 images.\n",
    "\n",
    "The dataset is divided into a set of **60,000 training examples** and a set of **10,000 evaluation examples**. Each example is a **28x28 grayscale image**, associated with a **label from 10 classes**. Zalando created this dataset with the intention of providing a replacement for the popular **MNIST** handwritten digits dataset. It is a useful addition as it is a bit more complex, but still very easy to use. It shares the same image size and train/test split structure as MNIST, and can therefore be used as a drop-in replacement. It requires minimal efforts on preprocessing and formatting the distinct images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "igSTsQMKWw1U"
   },
   "source": [
    "Let's download and inspect the training images of the dataset. Therefore, let's first define the directory in which we aim to store the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfCn1e8MWw1V"
   },
   "outputs": [],
   "source": [
    "train_path = data_directory + '/train_fmnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4fUsNeLWw1V"
   },
   "source": [
    "Now, let's download the training data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-GZL31YWw1W"
   },
   "outputs": [],
   "source": [
    "# download and transform training images\n",
    "fashion_mnist_train = torchvision.datasets.FashionMNIST(root=train_path, train=True, download=True)\n",
    "\n",
    "# split data (X) from labels (y)\n",
    "X_train = fashion_mnist_train.data\n",
    "y_train = fashion_mnist_train.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaLuUXc4Ww1W"
   },
   "source": [
    "Verify the number of training images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmRdyfxFWw1W"
   },
   "outputs": [],
   "source": [
    "# determine the number of training data images\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtbIaCpLWw1W"
   },
   "source": [
    "Furthermore, let's inspect a couple of the downloaded training images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gAtYOeUPWw1X"
   },
   "outputs": [],
   "source": [
    "# select some random image ids\n",
    "image_ids = np.random.randint(0, len(X_train), size=9)\n",
    "\n",
    "# retrieve images and labels\n",
    "images = X_train[image_ids]\n",
    "labels = y_train[image_ids]\n",
    "images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nfUMS402Ww1X"
   },
   "source": [
    "Ok, that doesn't seem right :). Let's plot the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDzFFyZfWw1X"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 3, figsize=(9, 9))\n",
    "ax = np.ravel(ax)\n",
    "\n",
    "for i in range(len(images)):\n",
    "    ax[i].imshow(images[i], cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3SSorDiP_uFc"
   },
   "source": [
    "Nice. Let's check what the corresponding ground truth labels are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we know that the numerical label is 6. Each image is associated with a label from 0 to 9, and this number represents one of the fashion items. So what does 6 mean? Is 6 a bag? A pullover? The order of the classes can be found on Zalando research's [github page](https://github.com/zalandoresearch/fashion-mnist). We need to map each numerical label to its fashion item, which will be useful throughout the lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weOc_Ceb_5dU"
   },
   "outputs": [],
   "source": [
    "fashion_classes = {0: 'T-shirt/top',\n",
    "                   1: 'Trouser',\n",
    "                   2: 'Pullover',\n",
    "                   3: 'Dress',\n",
    "                   4: 'Coat',\n",
    "                   5: 'Sandal',\n",
    "                   6: 'Shirt',\n",
    "                   7: 'Sneaker',\n",
    "                   8: 'Bag',\n",
    "                   9: 'Ankle boot'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ctD4Dl0C_7RE"
   },
   "source": [
    "So, now we can do the translation (we need `.item()` to turn the tensor into an integer) and use the labels as titles in our figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8KrM8rfKnHh"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3, 3, figsize=(9, 9))\n",
    "ax = np.ravel(ax)\n",
    "\n",
    "for i in range(len(images)):\n",
    "    ax[i].imshow(images[i], cmap='gray')\n",
    "    ax[i].set_title(fashion_classes[labels[i].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5fmhiuzWw1Y"
   },
   "source": [
    "Fantastic, right? Let's now define the directory in which we aim to store the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8G3eQFy3Ww1b"
   },
   "outputs": [],
   "source": [
    "eval_path = data_directory + '/eval_fmnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNNTmyI7Ww1b"
   },
   "source": [
    "And download the evaluation data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvIBdhlPWw1b"
   },
   "outputs": [],
   "source": [
    "# download and transform training images\n",
    "fashion_mnist_eval = torchvision.datasets.FashionMNIST(root=eval_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4skfCFEfWw1c"
   },
   "source": [
    "Let's also verify the number of evaluation images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq3rW2wKWw1c"
   },
   "outputs": [],
   "source": [
    "# determine the number of evaluation data images\n",
    "len(fashion_mnist_eval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the evaluation dataset into equally sized chunks as our validation and test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(fashion_mnist_eval.data, fashion_mnist_eval.targets, test_size=0.5, stratify=fashion_mnist_eval.targets, random_state=seed_value)\n",
    "X_val.shape, X_test.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucTxc7GGWw1c"
   },
   "source": [
    "## 4. Neural Network Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTQ_VZWaWw1d"
   },
   "source": [
    "In this section we, will implement the architecture of the **neural network** we aim to utilize to learn a model that is capable to classify the 28x28 pixel FashionMNIST images of fashion items. However, before we start the implementation let's briefly revisit the process to be established. The following cartoon provides a birds-eye view:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9i5LlBmiWw1d"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"https://github.com/mommermi/hft-kid-2024summer/blob/main/lab_03/process.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyofP39KWw1d"
   },
   "source": [
    "### 4.1 Implementation of the Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loUEinm1Ww1e"
   },
   "source": [
    "The neural network, which we name **'FashionMNISTNet'** consists of three **fully-connected layers** (including an “input layer” and two hidden layers). Furthermore, the **FashionMNISTNet** should encompass the following number of neurons per layer: 100 (layer 1), 50 (layer 2) and 10 (layer 3). Meaning the first layer consists of 100 neurons, the second layer of 50 neurons and third layer of 10 neurons (the number of digit classes we aim to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGxSr-77Ww1e"
   },
   "source": [
    "We will now start implementing the network architecture as a separate Python class. Implementing the network architectures as a **separate class** in Python is good practice in deep learning projects. It will allow us to create and train several instances of the same neural network architecture. This provides us, for example, the opportunity to evaluate different initializations of the network parameters or train models using distinct datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLrELu2EWw1f"
   },
   "outputs": [],
   "source": [
    "# implement the MNISTNet network architecture\n",
    "class FashionMNISTNet(nn.Module):\n",
    "    \n",
    "    # define the class constructor\n",
    "    def __init__(self):\n",
    "        \n",
    "        # call super class constructor\n",
    "        super(FashionMNISTNet, self).__init__()\n",
    "        \n",
    "        # specify fully-connected (fc) layer 1 - in 28*28, out 100\n",
    "        self.linear1 = nn.Linear(28*28, 100, bias=True) # the linearity W*x+b\n",
    "        \n",
    "        # specify fc layer 2 - in 100, out 50\n",
    "        self.linear2 = nn.Linear(100, 50, bias=True) # the linearity W*x+b\n",
    "        \n",
    "        # specify fc layer 3 - in 50, out 10\n",
    "        self.linear3 = nn.Linear(50, 10) # the linearity W*x+b\n",
    "        \n",
    "        # add a softmax to the last layer\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1) # the softmax\n",
    "\n",
    "        # relu non-linear activation function\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    # define network forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        # reshape image pixels\n",
    "        x = images.float().view(-1, 28*28)\n",
    "        \n",
    "        # define fc layer 1 forward pass\n",
    "        x = self.relu(self.linear1(x))\n",
    "        \n",
    "        # define fc layer 2 forward pass\n",
    "        x = self.relu(self.linear2(x))\n",
    "        \n",
    "        # define layer 3 forward pass\n",
    "        x = self.logsoftmax(self.linear3(x))\n",
    "        \n",
    "        # return forward pass result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcrCZgZqWw1g"
   },
   "source": [
    "Now, that we have implemented our first neural network we are ready to instantiate a network model to be trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfvFFCCHWw1g"
   },
   "outputs": [],
   "source": [
    "model = FashionMNISTNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efX9IOPSw8DZ"
   },
   "source": [
    "Let's push the initialized `FashionMNISTNet` model to the computing `device` that is enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W93HbADVw8qe"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yt4PtPLWw1g"
   },
   "source": [
    "Once the model is initialized, we can visualize the model structure and review the implemented network architecture by execution of the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF90-Nk1Ww1g"
   },
   "outputs": [],
   "source": [
    "# print the initialized architectures\n",
    "print('[LOG] FashionMNISTNet architecture:\\n\\n{}\\n'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFKJMIjKWw1g"
   },
   "source": [
    "Looks like intended? Brilliant! Finally, let's have a look into the number of model parameters that we aim to train in the next steps of the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFOWHzJ3Ww1h"
   },
   "outputs": [],
   "source": [
    "# init the number of model parameters\n",
    "num_params = 0\n",
    "\n",
    "# iterate over the distinct parameters\n",
    "for param in model.parameters():\n",
    "\n",
    "    # collect number of parameters\n",
    "    num_params += param.numel()\n",
    "    \n",
    "# print the number of model paramters\n",
    "print('[LOG] Number of to be trained FashionMNISTNet model parameters: {}.'.format(num_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY9rZQ7JWw1h"
   },
   "source": [
    "Ok, our \"simple\" FashionMNISTNet model already encompasses an impressive number 84'060 model parameters to be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pytnqULPWw1h"
   },
   "source": [
    "### 4.2 Specification of the Neural Network Loss Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bHpHWQ7JWw1h"
   },
   "source": [
    "Now that we have implemented the **FashionMNISTNet** we are ready to train the network. However, prior to starting the training, we need to define an appropriate loss function. Remember, we aim to train our model to learn a set of model parameters $\\theta$ that minimize the classification error of the true class $c^{i}$ of a given handwritten digit image $x^{i}$ and its predicted class $\\hat{c}^{i} = f_\\theta(x^{i})$ as faithfully as possible. \n",
    "\n",
    "Thereby, the training objective is to learn a set of optimal model parameters $\\theta^*$ that optimize $\\arg\\min_{\\theta} \\|C - f_\\theta(X)\\|$ over all training images in the FashionMNIST dataset. To achieve this optimization objective, one typically minimizes a loss function $\\mathcal{L_{\\theta}}$ as part of the network training. In this lab we use the **'Negative Log Likelihood (NLL)'** loss, defined by:\n",
    "\n",
    "$$\\mathcal{L}^{NLL}_{\\theta} (c_i, \\hat c_i) = - \\frac{1}{N} \\sum_{i=1}^N \\log (\\hat{c}_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ID9HqJJqWw1h"
   },
   "source": [
    "for a set of $n$-FashionMNIST images $x^{i}$, $i=1,...,n$ and their respective predicted class labels $\\hat{c}^{i}$. This is summed for all the correct classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcObuMZfWw1i"
   },
   "source": [
    "During training the **NLL** loss will penalize models that result in a high classification error between the predicted class labels $\\hat{c}^{i}$ and their respective true class label $c^{i}$. Luckily, an implementation of the NLL loss is already available in PyTorch! It can be instantiated \"off-the-shelf\" via the execution of the following PyTorch command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbgFFIDjWw1i"
   },
   "outputs": [],
   "source": [
    "# define the optimization criterion / loss function\n",
    "nll_loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbspDM2dxGrO"
   },
   "source": [
    "Let's also push the initialized `nll_loss` computation to the computing `device` that is enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgKeoEcaxIdB"
   },
   "outputs": [],
   "source": [
    "nll_loss = nll_loss.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJhKTaHnWw1i"
   },
   "source": [
    "## 5. Neural Network Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRwd3R8XWw1i"
   },
   "source": [
    "In this section, we will train our neural network model (as implemented in the section above) using the transformed images of fashion items. More specifically, we will have a detailed look into the distinct training steps as well as how to monitor the training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKbH8GgrWw1i"
   },
   "source": [
    "### 5.1. Preparing the Network Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1K23pmmEWw1j"
   },
   "source": [
    "So far, we have pre-processed the dataset, implemented the ANN and defined the classification error. Let's now start to train a corresponding model for **10 epochs** and a **mini-batch size of 128** FashionMNIST images per batch. This implies that the whole dataset will be fed to the ANN 10 times in chunks of 128 images yielding to **469 mini-batches** (60.000 images / 128 images per mini-batch) per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bMEnxc1Ww1j"
   },
   "outputs": [],
   "source": [
    "# specify the training parameters\n",
    "num_epochs = 10 # number of training epochs\n",
    "mini_batch_size = 128 # size of the mini-batches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jX99_DY7Ww1j"
   },
   "source": [
    "Based on the loss magnitude of a certain mini-batch PyTorch automatically computes the gradients. But even better, based on the gradient, the library also helps us in the optimization and update of the network parameters $\\theta$.\n",
    "\n",
    "We will use the **Stochastic Gradient Descent (SGD) optimization** and set the learning-rate $l = 0.0001$. Each mini-batch step the optimizer will update the model parameters $\\theta$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84Oq2woEWw1j"
   },
   "outputs": [],
   "source": [
    "# define learning rate and optimization strategy\n",
    "learning_rate = 0.0001\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX8MBSDxWw1k"
   },
   "source": [
    "Now that we have successfully implemented and defined the three ANN building blocks let's take some time to review the `FashionMNISTNet` model definition as well as the `loss`. Please, read the above code and comments carefully and don't hesitate to let us know any questions you might have."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XO1P2wb3Ww1k"
   },
   "source": [
    "Furthermore, let's specify and instantiate PyTorch data loaders for the different splits (the mini batch sizes for val and test equal the sizes of these datasets for quicker processing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyLwFEMXWw1l"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_train_dataloader = torch.utils.data.DataLoader(list(zip(X_train, y_train)), batch_size=mini_batch_size, shuffle=True)\n",
    "fashion_mnist_val_dataloader = torch.utils.data.DataLoader(list(zip(X_val, y_val)), batch_size=len(X_val), shuffle=True)\n",
    "fashion_mnist_test_dataloader = torch.utils.data.DataLoader(list(zip(X_test, y_test)), batch_size=len(X_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tp6hmrg7Ww1l"
   },
   "source": [
    "### 5.2. Running the Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov5Z6NLvWw1m"
   },
   "source": [
    "Finally, we start training the model. The detailed training procedure for each mini-batch is performed as follows: \n",
    "\n",
    ">1. do a forward pass through the FashionMNISTNet network, \n",
    ">2. compute the negative log likelihood classification error $\\mathcal{L}^{NLL}_{\\theta}(c^{i};\\hat{c}^{i})$, \n",
    ">3. do a backward pass through the FashionMNISTNet network, and \n",
    ">4. update the parameters of the network $f_\\theta(\\cdot)$.\n",
    "\n",
    "To ensure learning while training our ANN model, we will monitor whether the loss decreases with progressing training. Therefore, we obtain and evaluate the classification performance of the entire training dataset after each training epoch. Based on this evaluation, we can conclude on the training progress and whether the loss is converging (indicating that the model might not improve any further).\n",
    "\n",
    "The following elements of the network training code below should be given particular attention:\n",
    " \n",
    ">- `loss.backward()` computes the gradients based on the magnitude of the reconstruction loss,\n",
    ">- `optimizer.step()` updates the network parameters based on the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70W8AZWlWw1m"
   },
   "outputs": [],
   "source": [
    "# init collection of training epoch losses\n",
    "train_epoch_losses = []\n",
    "\n",
    "# set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# train the MNISTNet model\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # init collection of mini-batch losses\n",
    "    train_mini_batch_losses = []\n",
    "    \n",
    "    # iterate over all-mini batches\n",
    "    for i, (images, labels) in enumerate(fashion_mnist_train_dataloader):\n",
    "    \n",
    "        # push mini-batch data to computation device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # run forward pass through the network\n",
    "        output = model(images)\n",
    "\n",
    "        # reset graph gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # determine classification loss\n",
    "        loss = nll_loss(output, labels)\n",
    "        \n",
    "        # run backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update network paramaters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # collect mini-batch reconstruction loss\n",
    "        train_mini_batch_losses.append(loss.data.item())\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "    \n",
    "    # print epoch loss\n",
    "    now = datetime.now().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] epoch: {} train-loss: {}'.format(str(now), str(epoch), str(train_epoch_loss)))\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_losses.append(train_epoch_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8dqoGo_7Ww1m"
   },
   "source": [
    "Upon successful training let's visualize and inspect the training loss per epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLI0Y53VWw1m"
   },
   "outputs": [],
   "source": [
    "# prepare plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# add grid\n",
    "ax.grid(linestyle='dotted')\n",
    "\n",
    "# plot the training epochs vs. the epochs' classification error\n",
    "ax.plot(np.array(range(1, len(train_epoch_losses)+1)), train_epoch_losses, label='epoch loss (blue)')\n",
    "\n",
    "# add axis legends\n",
    "ax.set_xlabel(\"Epoch]\")\n",
    "ax.set_ylabel(\"Training Loss\")\n",
    "\n",
    "# add plot title\n",
    "plt.title('Training Epochs $e_i$ vs. Classification Error $L^{NLL}$', fontsize=10);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QmkQMB6YWw1n"
   },
   "source": [
    "Ok, fantastic. The training error is nicely going down. We could train the network a couple more epochs until the error converges. But let's stay with the 10 training epochs for now and continue with evaluating our trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nyWq1X-Ww1n"
   },
   "source": [
    "## 6. Neural Network Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPP7OowBWw1o"
   },
   "source": [
    "We will now evaluate the trained model using the same mini-batch approach as we did throughout the network training and derive the mean negative log-likelihood loss of the mini-batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpttWy_AWw1o"
   },
   "outputs": [],
   "source": [
    "# set the model in eval mode\n",
    "model.eval()\n",
    "\n",
    "# move the model to the cpu (for evaluation, we will not need the gpu)\n",
    "model.to('cpu')\n",
    "\n",
    "# init collection of mini-batch losses\n",
    "eval_mini_batch_losses = []\n",
    "\n",
    "# iterate over all-mini batches\n",
    "for i, (images, labels) in enumerate(fashion_mnist_test_dataloader):\n",
    "\n",
    "    # run forward pass through the network\n",
    "    output = model(images)\n",
    "\n",
    "    # determine classification loss\n",
    "    loss = nll_loss(output, labels)\n",
    "\n",
    "    # collect mini-batch reconstruction loss\n",
    "    eval_mini_batch_losses.append(loss.data.item())\n",
    "\n",
    "# determine mean min-batch loss of epoch\n",
    "eval_loss = np.mean(eval_mini_batch_losses)\n",
    "\n",
    "# print epoch loss\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] eval-loss: {}'.format(str(now), str(eval_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNwLBDGPWw1p"
   },
   "source": [
    "Ok, great. The evaluation loss looks in-line with our training loss. Let's now inspect a few sample predictions to get an impression of the model quality. Therefore, we will again pick a random image of our evaluation dataset and retrieve its PyTorch tensor as well as the corresponding label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTM5mTHaWw1p"
   },
   "outputs": [],
   "source": [
    "# set (random) image id\n",
    "image_id = 1000\n",
    "\n",
    "# retrieve image exhibiting the image id\n",
    "image, label = X_test[image_id], y_test[image_id]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Hjz4GOpyWw1q"
   },
   "source": [
    "Let's show the image and the corresponding ground truth label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1hZMQ6oWw1r"
   },
   "outputs": [],
   "source": [
    "# set image plot title \n",
    "plt.title('Example: {}, Label: {}'.format(str(image_id), fashion_classes[label.item()]))\n",
    "\n",
    "# plot mnist handwritten digit sample\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFW-PYEnWw1r"
   },
   "source": [
    "Let's compare the true label with the prediction of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfaV80IpWw1s"
   },
   "outputs": [],
   "source": [
    "model(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNFAM_deWw1s"
   },
   "source": [
    "We can even determine the likelihood of the most probable class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A2knLiUqWw1t"
   },
   "outputs": [],
   "source": [
    "most_probable = torch.argmax(model(image), dim=1).item()\n",
    "print('Most probable class: {}'.format(most_probable))\n",
    "print('This class represents the following fashion article: {}'.format(fashion_classes[most_probable]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwOIf2adWw1t"
   },
   "source": [
    "Let's now obtain the predictions for all the fashion item images of the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRmjfYDZWw1t"
   },
   "outputs": [],
   "source": [
    "predictions = torch.argmax(model(X_test), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFKiMKw-Ww1t"
   },
   "source": [
    "Furthermore, let's obtain the overall classifcation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvV-HLcsWw1t"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6B-KdgKNWw1u"
   },
   "source": [
    "Let's also inspect the confusion matrix to determine major sources of misclassification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5LkSBwpWw1u"
   },
   "outputs": [],
   "source": [
    "# determine classification matrix of the predicted and target classes\n",
    "mat = confusion_matrix(y_test, predictions.detach())\n",
    "\n",
    "# initialize the plot and define size\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# plot corresponding confusion matrix\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, cmap='YlOrRd_r', xticklabels=fashion_classes.values(), yticklabels=fashion_classes.values())\n",
    "plt.tick_params(axis='both', which='major', labelsize=8, labelbottom = False, bottom=False, top = False, left = False, labeltop=True)\n",
    "\n",
    "# set plot title\n",
    "plt.title('Fashion MNIST classification matrix')\n",
    "\n",
    "# set axis labels\n",
    "plt.xlabel('[true label]')\n",
    "plt.ylabel('[predicted label]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob6vR-e3Ww1u"
   },
   "source": [
    "Ok, we can easily see that our current model confuses sandals with either sneakers or ankle boots. However, the inverse does not really hold. The model sometimes confuses sneakers with ankle boots, and only very rarely with sandals. The same holds ankle boots. Our model also has issues distinguishing shirts from coats (and, to a lesser degree, from T-shirts and pullovers).\n",
    "\n",
    "These mistakes are not very surprising, as these items exhibit a high similarity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "e1l8HbUzWw1v"
   },
   "source": [
    "## 7. Final Notes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "S3P5e48aWw1w"
   },
   "source": [
    "In this lab we did not really tune the hyperparameter of our neural network (the learning rate); therefore, we did not make use of the validation dataset. You can implement hyperparameter tuning (learning rate) and checking for overfitting as your home assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "aut1dJXmWw1O",
    "Ks081EJEWw1P",
    "vyqnqndjWw1S",
    "ucTxc7GGWw1c",
    "hJhKTaHnWw1i",
    "8nyWq1X-Ww1n",
    "e1l8HbUzWw1v"
   ],
   "name": "lab_04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
